{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyFirstMLP.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kaitlynmcgoldrick/ai-for-social-good-lab/blob/master/MyFirstMLP.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "PGroYPZ7iKnB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "metadata": {
        "id": "PWt9oJDQvTaI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### To do\n",
        "\n",
        "\n",
        "\n",
        "*   Include time elapsed to train each epoch - done\n",
        "*   Find way to compare the prediction and target - done\n",
        "*   Import to my own machine using Jupyter ?\n",
        "*   Upload my own image and see how it performs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WR0wK8H1pRyu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import and install dependencies"
      ]
    },
    {
      "metadata": {
        "id": "Ww4gExynCHk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "01aea8a5-cad6-4079-9917-ca0385f60a09"
      },
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import io\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from matplotlib.pyplot import cm \n",
        "\n",
        "def install_pytorch():\n",
        "    os = platform.system()\n",
        "    if os == \"Linux\":\n",
        "        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
        "    elif os == \"Windows\":\n",
        "        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl \n",
        "    !pip3 install torchvision\n",
        "\n",
        "\n",
        "# Install PyTorch.\n",
        "install_pytorch()\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.0 from http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iXansoVmiU6z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "WKQNHhvBCaEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "\n",
        "training_data = torchvision.datasets.MNIST('processed/training.pt', download=True, train=True, transform = torchvision.transforms.ToTensor())\n",
        "\n",
        "test_data = torchvision.datasets.MNIST('processed/test.pt', download=True, train=True, transform = torchvision.transforms.ToTensor())\n",
        "\n",
        "# Batch sizes\n",
        "\n",
        "train_batch_size = 1000\n",
        "eval_batch_size = 1000\n",
        "\n",
        "# Data loader\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_data, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=eval_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lk9OBbT0phYb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Shows how flattening works"
      ]
    },
    {
      "metadata": {
        "id": "eayynMz5wgP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf85ec3b-3aa8-46d1-ac8b-228cdacacde2"
      },
      "cell_type": "code",
      "source": [
        "dd = list(training_loader)\n",
        "image_batch = dd[0][0]\n",
        "image_batch.shape\n",
        "image_batch = image_batch.view([-1, 28*28])\n",
        "image_batch.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "bpWH-cT9pzsa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plot an image for better understanding"
      ]
    },
    {
      "metadata": {
        "id": "eSk4IDRUJqDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "f4dce552-6a41-4b80-c194-503bb3dcd7fc"
      },
      "cell_type": "code",
      "source": [
        "first_image = training_data[54534][0]\n",
        "first_image.shape\n",
        "\n",
        "#Necessary to squeeze before plotting\n",
        "first_image = torch.squeeze(first_image)\n",
        "\n",
        "plt.imshow(first_image)\n",
        "plt.show()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQAYEEsAMPg/xH9aoioPmm8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f38e6cd6d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fhk29iuzikeF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. MLP"
      ]
    },
    {
      "metadata": {
        "id": "A5aLLl-gnONJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## My Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "ufAxsf05inw3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class myNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(myNeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 800) # fully connected\n",
        "        self.fc2 = nn.Linear(800, 600) # fully connected\n",
        "        self.fc3 = nn.Linear(600, 100) # fully connected\n",
        "        self.fc4 = nn.Linear(100, 10) # fully connected\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # see the sketch above. \n",
        "        out = F.relu(self.fc1(x))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.relu(self.fc3(out))\n",
        "        out = self.fc4(out)\n",
        "    \n",
        "        return out\n",
        "    \n",
        "my_neural_net = myNeuralNet()\n",
        "\n",
        "# Turn on eval mode by default\n",
        "my_neural_net = my_neural_net.eval()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2M3CF1hqGWl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Show initial prediction matrix"
      ]
    },
    {
      "metadata": {
        "id": "2qI5TUfby3Aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "39ece649-feda-472f-d706-3e53116bec81"
      },
      "cell_type": "code",
      "source": [
        "prediction = my_neural_net(image_batch)\n",
        "prediction[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.00000e-02 *\n",
              "       [-9.1066,  0.2002,  0.3513, -3.7047, -8.9668,  3.9845,  1.3294,\n",
              "        -9.8125, -7.0767, -6.3484])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "Ic7s65qqdM4e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Cost Function"
      ]
    },
    {
      "metadata": {
        "id": "x1_cFLHHdK5G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def cost_function(prediction, target):\n",
        "    loss = F.cross_entropy(prediction, target)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wwai9PZAdSLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Optimizer "
      ]
    },
    {
      "metadata": {
        "id": "7-R9nb0Udc0n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(my_neural_net.parameters(), lr=0.01) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLkacA3HmdMG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Training Function"
      ]
    },
    {
      "metadata": {
        "id": "iNlpQgzhpigf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_training_func(epoch, model, training_loader, optimizer):\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  start_time = time.time()\n",
        "  for i, (data, target) in enumerate(training_loader):\n",
        "\n",
        "    # Make te gradients all zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Flatten the batch \n",
        "    data = data.view([-1, 28*28])\n",
        "\n",
        "    # Evaluate the model \n",
        "    predictions = model(data)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = cost_function(predictions, target)\n",
        "\n",
        "    # Compute the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Accumulate the loss of each mini batch\n",
        "    total_loss += loss.data[0]*len(data)\n",
        "\n",
        "    # Compute the accuracy per minibatch\n",
        "    pred_classes = predictions.data.max(1, keepdim=True)[1]\n",
        "    correct += pred_classes.eq(target.data.view_as(pred_classes)).sum().double()\n",
        "    \n",
        "  # Compute the mean loss for each epoch\n",
        "  average_loss = total_loss/len(training_loader.dataset)\n",
        "  \n",
        "  # Compute the accuracy for each epoch \n",
        "  epoch_accuracy = correct/len(training_loader.dataset)\n",
        "  \n",
        "  # Compute time elapsed \n",
        "  elapsed_time = (time.time() - start_time)\n",
        "  \n",
        "  print(\"Time Elapsed: {:.2f}s\".format(elapsed_time))\n",
        "  print(\"Training Epoch: #{}\".format(epoch))\n",
        "  print(\"Average Loss: {:.5f}\".format(average_loss))\n",
        "  print(\"Epoch Accuracy: {:.3f}%\".format(100.*epoch_accuracy))\n",
        "  print(\"\\n\")\n",
        "  \n",
        "  return average_loss, epoch_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mgAyvP1Amfzh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Evaluation Function"
      ]
    },
    {
      "metadata": {
        "id": "wRwVvqzmnL9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_eval_func(model, test_loader):\n",
        "    \n",
        "    # set the model in .eval() mode \n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    # iterate over all the mini-batches \n",
        "    for i, (data, target) in enumerate(test_loader):\n",
        "\n",
        "        # Flatten the batch \n",
        "        data = data.view([-1, 28*28])\n",
        "        \n",
        "        # Execute the model\n",
        "        predictions = model(data)\n",
        "        # Compute the loss\n",
        "        loss = cost_function(predictions, target) \n",
        "        \n",
        "        # Accumulate the loss of each minibatch\n",
        "        total_loss += loss.data[0]*len(data)\n",
        "        \n",
        "        # Compute the accuracy per minibatch  \n",
        "        pred_classes = predictions.data.max(1, keepdim=True)[1]\n",
        "\n",
        "        correct += pred_classes.eq(target.data.view_as(pred_classes)).sum().double()\n",
        "    \n",
        "    # Compute the mean loss for each epoch\n",
        "    average_loss = total_loss/len(test_loader.dataset)\n",
        "    \n",
        "    # Compute the accuracy for each epoch\n",
        "    accuracy = correct/len(test_loader.dataset)\n",
        "        \n",
        "    print(\"Average Loss: {:.5f}\".format(average_loss))\n",
        "    print(\"Accuracy: {:.3f}%\".format(100.*accuracy))\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    return average_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "orhTQySgmL2p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Checkpointing"
      ]
    },
    {
      "metadata": {
        "id": "K6RIgS2VjbR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model(epoch, model, path='./'):\n",
        "    \n",
        "    # file name and path \n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # load the model parameters \n",
        "    torch.save(model.state_dict(), filename)\n",
        "    \n",
        "    \n",
        "    return model\n",
        "\n",
        "  \n",
        "def load_model(epoch, model, path='./'):\n",
        "    \n",
        "    # file name and path \n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # load the model parameters \n",
        "    model.load_state_dict(torch.load(filename))\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9cfXgjGonma0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Perform Training"
      ]
    },
    {
      "metadata": {
        "id": "EsRRoisLnpAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "9b028608-8ca9-441c-ac2e-2634a0bdfafe"
      },
      "cell_type": "code",
      "source": [
        "# Number of epochs \n",
        "#hyperparameter\n",
        "numEpochs = 5;\n",
        "\n",
        "# checkpoint frequency \n",
        "checkpoint_freq = 10\n",
        "\n",
        "# path to save the data \n",
        "path = './'\n",
        "\n",
        "# empty lists \n",
        "training_losses = []\n",
        "\n",
        "training_accuracies = []\n",
        "\n",
        "# Repeat training for each epoch\n",
        "for epoch in range(1, numEpochs + 1):\n",
        "    \n",
        "    # train() function (see above)\n",
        "    train_loss, train_acc = my_training_func(epoch, my_neural_net, training_loader, optimizer)    \n",
        "    \n",
        "    # append lists for plotting and printing \n",
        "    training_losses.append(train_loss)    \n",
        "    \n",
        "    training_accuracies.append(train_acc)    \n",
        "    \n",
        "    # Checkpoint\n",
        "    if epoch % checkpoint_freq ==0:\n",
        "        save_model(epoch, neural_net, path)\n",
        "\n",
        "# Last checkpoint\n",
        "save_model(numEpochs, my_neural_net, path)\n",
        "    \n",
        "print(\"\\nOptimization ended.\\n\")  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Elapsed: 11.96s\n",
            "Training Epoch: #1\n",
            "Average Loss: 0.55804\n",
            "Epoch Accuracy: 81.760%\n",
            "\n",
            "\n",
            "Time Elapsed: 11.69s\n",
            "Training Epoch: #2\n",
            "Average Loss: 0.11805\n",
            "Epoch Accuracy: 96.457%\n",
            "\n",
            "\n",
            "Time Elapsed: 11.77s\n",
            "Training Epoch: #3\n",
            "Average Loss: 0.07843\n",
            "Epoch Accuracy: 97.537%\n",
            "\n",
            "\n",
            "Time Elapsed: 11.76s\n",
            "Training Epoch: #4\n",
            "Average Loss: 0.05896\n",
            "Epoch Accuracy: 98.153%\n",
            "\n",
            "\n",
            "Time Elapsed: 11.79s\n",
            "Training Epoch: #5\n",
            "Average Loss: 0.04722\n",
            "Epoch Accuracy: 98.432%\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zYP-c4d6uBCK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the performance with our Test data"
      ]
    },
    {
      "metadata": {
        "id": "vH-EYkOw5nhx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_single(model, single_test_data):\n",
        "    \n",
        "    data = single_test_data[0]\n",
        "    \n",
        "    # set the model in .eval() mode \n",
        "    model.eval()\n",
        "    \n",
        "    # Flatten the batch \n",
        "    data = data.view([-1, 28*28])\n",
        "    \n",
        "    prediction = model(data)\n",
        "    \n",
        "    pred_classes = prediction.data.max(1, keepdim=True)[1]\n",
        "    \n",
        "    return pred_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwGttgMtrBz3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Look at prediction vs actual for one data point"
      ]
    },
    {
      "metadata": {
        "id": "f4q173XUxfUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99062989-a84c-404e-f591-cde86d1a9d09"
      },
      "cell_type": "code",
      "source": [
        "dd = list(test_data)\n",
        "# print(dd[0][0])\n",
        "\n",
        "first_image = dd[4][0]\n",
        "first_image = torch.squeeze(first_image)\n",
        "print(dd[4][1])\n",
        "plt.imshow(first_image)\n",
        "plt.show()\n",
        "\n",
        "test = dd[7005]\n",
        "\n",
        "prediction = eval_single(my_neural_net, test)\n",
        "print(\"Prediction:\", prediction)\n",
        "print(\"Actual:\", test[1])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: tensor([[ 2]])\n",
            "Actual: tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vH40NTmHq6KA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Determine Accuracy with Test Data Set"
      ]
    },
    {
      "metadata": {
        "id": "k3YxzzxS6Hzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3b2f70a7-16ef-4bc0-9ca1-c0518eb3d76e"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = my_eval_func(my_neural_net, test_loader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss: 0.03585\n",
            "Accuracy: 98.882%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}